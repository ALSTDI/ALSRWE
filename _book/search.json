[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ALS-RWE: A Living Resource for ALS Real World Evidence",
    "section": "",
    "text": "1 Welcome to ALS RWE\nThis is the introduction to your Quarto book.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome</span>"
    ]
  },
  {
    "objectID": "approach.html",
    "href": "approach.html",
    "title": "2  Our Approach",
    "section": "",
    "text": "3 Our approach\nWith the increasing adoption of standardized data frameworks, many organizations are now transforming their electronic health records into common data models (CDM) such as the Observational Medical Outcomes Partnership (OMOP). The OMOP extract, transform, and load (ETL) process is complex and necessitates collaboration among diverse stakeholders (data engineers, clinical informaticists, clinicians, and health system leadership), each with different technical backgrounds and professional obligations. A common challenge is translating technical knowledge across these diverse groups, often hindered by the “curse of knowledge.” Here, we describe the best practices for coordinating a large-scale international OMOP project, including a proposed theoretical framework for ensuring implementation readiness of participating sites. The STARDUSTT framework (Secure Data, Technology Awareness, Relational Databases, Data Quality, Utilization of GitHub, Standardized Vocabularies, Training & Documentation, Translation and Communication) represents a structured approach to support CDM implementation projects that can be applied in a variety of settings.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Our Approach</span>"
    ]
  },
  {
    "objectID": "approach.html#table-1-strategies-for-resolving-common-problems-in-omop-implementation-projects",
    "href": "approach.html#table-1-strategies-for-resolving-common-problems-in-omop-implementation-projects",
    "title": "2  Our Approach",
    "section": "4.1 Table 1: Strategies for Resolving Common Problems in OMOP Implementation Projects",
    "text": "4.1 Table 1: Strategies for Resolving Common Problems in OMOP Implementation Projects\n\n\n\n\n\n\n\n\nProblem\nImpact\nStrategy\n\n\n\n\nTeam members have varying levels of expertise\nLeaders have trouble making decisions\nLevel the playing field by starting with fundamental knowledge\n\n\nOHDSI educational resources are overwhelming\nLearners are overwhelmed\nProvide curated, annotated resources targeted for specific needs\n\n\nTechnical jargon is confusing\nMiscommunication and misunderstandings\nSimplify communication by using accessible language\n\n\nJumping into complex topics too quickly\nFrustration and disengagement\nBuild knowledge incrementally\n\n\nPassive learning methods\nLower retention of information and skills\nProvide engaging, active learning exercises\n\n\nLack of regular feedback\nPersistent misunderstandings and slow progress\nRegular check-ins and open lines of communication\n\n\nOne-size-fits-all teaching methods\nInconsistent learning outcomes\nDevelop diverse teaching methods\n\n\nIncomplete or unclear documentation\nDifficulty in applying learned concepts\nProvide clear, accessible documentation\n\n\nIsolated learning limits knowledge sharing\nSlower problem-solving and innovation\nEncourage mentorship and peer-to-peer learning\n\n\nTheoretical learning lacks practical application\nDifficulty applying knowledge to real tasks\nFocus on real-world applications through case studies\n\n\nStatic training programs\nTraining may not address current needs\nContinuously improve, adapt, and refine learning materials",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Our Approach</span>"
    ]
  },
  {
    "objectID": "approach.html#secure-data",
    "href": "approach.html#secure-data",
    "title": "2  Our Approach",
    "section": "6.1 Secure Data",
    "text": "6.1 Secure Data\nSecure Data technical support and training emphasize the importance of data protection practices, including de-identification techniques and robust data security measures to protect personal health information (PHI) within the OMOP CDM.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Our Approach</span>"
    ]
  },
  {
    "objectID": "approach.html#technology-awareness",
    "href": "approach.html#technology-awareness",
    "title": "2  Our Approach",
    "section": "6.2 Technology Awareness",
    "text": "6.2 Technology Awareness\nTechnology Awareness covers essential tools and technologies like Docker Containers, SQL, and other coding practices that are crucial for data management and analysis. This component provides team members with the technical skills needed to navigate and utilize OHDSI tools effectively.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Our Approach</span>"
    ]
  },
  {
    "objectID": "approach.html#active-clinical-representation",
    "href": "approach.html#active-clinical-representation",
    "title": "2  Our Approach",
    "section": "6.3 Active Clinical Representation",
    "text": "6.3 Active Clinical Representation\nActive clinical representation ensures nuanced understanding of clinical workflows and documentation practices. Interdisciplinary teams of physicians, nurses, and other clinicians should be part of the core functional team working closely with technical experts and data scientists.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Our Approach</span>"
    ]
  },
  {
    "objectID": "approach.html#relational-databases",
    "href": "approach.html#relational-databases",
    "title": "2  Our Approach",
    "section": "6.4 Relational Databases",
    "text": "6.4 Relational Databases\nRelational Databases training focuses on the structure, management, and querying of databases. Technical support includes foundational courses on relational database concepts, SQL querying, and schema design.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Our Approach</span>"
    ]
  },
  {
    "objectID": "approach.html#data-quality",
    "href": "approach.html#data-quality",
    "title": "2  Our Approach",
    "section": "6.5 Data Quality",
    "text": "6.5 Data Quality\nData Quality addresses the importance of maintaining high data accuracy, consistency, and reliability. This component emphasizes the foundation of data quality in electronic health records for secondary use.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Our Approach</span>"
    ]
  },
  {
    "objectID": "approach.html#utilization-of-github",
    "href": "approach.html#utilization-of-github",
    "title": "2  Our Approach",
    "section": "6.6 Utilization of GitHub",
    "text": "6.6 Utilization of GitHub\nUtilization of GitHub introduces version control systems, enhancing collaboration and efficient project management. Training covers basics of version control, repository management, and reporting issues. By learning to use GitHub effectively, team members can collaborate on projects more efficiently and maintain better control over project versions and changes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Our Approach</span>"
    ]
  },
  {
    "objectID": "approach.html#standardized-vocabularies",
    "href": "approach.html#standardized-vocabularies",
    "title": "2  Our Approach",
    "section": "6.7 Standardized Vocabularies",
    "text": "6.7 Standardized Vocabularies\nStandardized vocabularies cover the use and application of standardized terminologies and classifications to ensure data consistency and interoperability. This includes training on vocabularies such as SNOMED, LOINC, and RxNorm, for projects involving the OMOP CDM, as well as exposure to the OHDSI Athena tool.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Our Approach</span>"
    ]
  },
  {
    "objectID": "approach.html#training-documentation",
    "href": "approach.html#training-documentation",
    "title": "2  Our Approach",
    "section": "6.8 Training & Documentation",
    "text": "6.8 Training & Documentation\nTraining & Documentation provides all team members access to clear, accessible resources and diverse learning methods to cater to different learning styles. This component includes providing comprehensive documentation, training materials, and continuous updates based on emerging technologies. Emphasizing rigorous research techniques, such as protocols, Manuals of Procedures (MOPs), and Standard Operating Procedures (SOPs), promotes standardization and reproducibility, just like in any well-conducted study.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Our Approach</span>"
    ]
  },
  {
    "objectID": "approach.html#translation-communication",
    "href": "approach.html#translation-communication",
    "title": "2  Our Approach",
    "section": "6.9 Translation & Communication",
    "text": "6.9 Translation & Communication\nTranslation & Communication bridges linguistic and cultural gaps in global health data projects. This involves translating training materials, documentation, and resources, and building cross-cultural competencies within teams. Effective communication ensures accurate conveyance of clinical, technical, and operational practices, fostering cohesive, multilingual, and multicultural team dynamics.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Our Approach</span>"
    ]
  },
  {
    "objectID": "approach.html#table-2-applying-the-stardustt-framework-to-various-personas",
    "href": "approach.html#table-2-applying-the-stardustt-framework-to-various-personas",
    "title": "2  Our Approach",
    "section": "7.1 Table 2: Applying the STARDUSTT Framework to Various Personas",
    "text": "7.1 Table 2: Applying the STARDUSTT Framework to Various Personas\n\n\n\n\n\n\n\n\n\nComponent\nC-Suite Executives\nPhysician/Nurse Clinical Informaticists\nData Engineers\n\n\n\n\nSecure Data\nEmphasizing data security, privacy, and compliance with regulations like HIPAA\nFocusing on data de-identification and IRB compliance for PHI within OMOP CDM\nTraining on advanced data protection practices, including de-identification\n\n\nTechnology Awareness\nIntroducing Broadsea and OHDSI tools, outlining strategic value and ROI\nKnowledge of OHDSI tools like Broadsea, Data Quality Dashboard, Usagi, and their clinical use\nComprehensive training on essential technologies like Broadsea and OHDSI tools\n\n\nActive Clinical Representation\nSupporting interdisciplinary collaboration through protected effort\nBridging communication between clinical experts and technical team for understanding data provenance\n\n\n\nRelational Databases\nExplaining strategic importance for data management and decision-making\nTraining on navigating and querying databases relevant to clinical data\nOffering customized scripts for SQL dialect and OMOP CDM version\n\n\nData Quality\nHighlighting impact of high-quality data on strategic goals and operational efficiency\nEmphasizing OHDSI tools for data cleaning, validation, and standardization\nDetailed training on OHDSI data quality, Book of OHDSI, curated resources, and OHDSI community\n\n\nUtilization of GitHub\nDemonstrating value of version control for efficient project management\nSimplifying version control systems for data and collaboration management\nWorkshops on advanced GitHub functionalities, repository management, open-source contributions\n\n\nStandardized Vocabularies\nImportance of vocabularies for data consistency and interoperability in strategic planning\nTraining on vocabularies like SNOMED, LOINC, RxNorm for clinical data management\nTraining on vocabularies to ensure accurate data mapping and analysis within OHDSI\n\n\nTraining & Documentation\nExecutive summaries, reinforcing learning and knowledge sharing\nClinical data guides, glossaries, connections with senior informaticists\nTechnical tutorials, coding workshops, collaborative projects, detailed manuals, peer coding reviews\n\n\nTranslation & Communication\nEmphasizing clear cross-functional and cross-cultural communication for alignment and cohesion\nTraining on effective cross-disciplinary communication, including strategies for engaging non-technical stakeholders\nEnsuring clarity in technical documentation, promoting best practices for collaborative communication across technical and non-technical team members",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Our Approach</span>"
    ]
  },
  {
    "objectID": "trainings.html",
    "href": "trainings.html",
    "title": "3  New to RWE",
    "section": "",
    "text": "4 Our approach\nOur approach.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>New to RWE</span>"
    ]
  },
  {
    "objectID": "GIS.html",
    "href": "GIS.html",
    "title": "ALS-RWE: A Living Resource for ALS Real World Evidence",
    "section": "",
    "text": "q",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>GIS.html</span>"
    ]
  },
  {
    "objectID": "ohdsi-omop.html",
    "href": "ohdsi-omop.html",
    "title": "5  OHDSI and OMOP",
    "section": "",
    "text": "6 Introduction to OHDSI/OMOP\nObservational Health….",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>OHDSI and OMOP</span>"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "6  Resources",
    "section": "",
    "text": "7 Resources",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#analytic-use-cases-and-examples",
    "href": "resources.html#analytic-use-cases-and-examples",
    "title": "6  Resources",
    "section": "11.1 Analytic Use Cases and Examples",
    "text": "11.1 Analytic Use Cases and Examples\n\n\n\n\n\n\n\n\n\nAnalytic use case\nType\nStructure\nExample\n\n\n\n\nClinical characterization\nDisease Natural History\nAmongst patients who are diagnosed with &lt;insert your favorite disease&gt;, what are the patient’s characteristics from their medical history?\nAmongst patients with rheumatoid arthritis, what are their demographics (age, gender), prior conditions, medications, and health service utilization behaviors?\n\n\n\nTreatment utilization\nAmongst patients who have &lt;insert your favorite disease&gt;, which treatments were patients exposed to amongst &lt;list of treatments for disease&gt; and in which sequence?\nAmongst patients with depression, which treatments were patients exposed to SSRI, SNRI, TCA, bupropion, esketamine and in which sequence?\n\n\n\nOutcome incidence\nAmongst patients who are new users of &lt;insert your favorite drug&gt;, how many patients experienced &lt;insert your favorite known adverse event from the drug profile&gt; within &lt;time horizon following exposure start&gt;?\nAmongst patients who are new users of methylphenidate, how many patients experienced psychosis within 1 year of initiating treatment?\n\n\nPopulation-level effect estimation\nSafety surveillance\nDoes exposure to &lt;insert your favorite drug&gt; increase the risk of experiencing &lt;insert an adverse event&gt; within &lt;time horizon following exposure start&gt;?\nDoes exposure to ACE inhibitor increase the risk of experiencing Angioedema within 1 month after exposure start?\n\n\n\nComparative effectiveness\nDoes exposure to &lt;insert your favorite drug&gt; have a different risk of experiencing &lt;insert any outcome (safety or benefit)&gt; within &lt;time horizon following exposure start&gt;, relative to &lt;insert your comparator treatment&gt;?\nDoes exposure to ACE inhibitor have a different risk of experiencing acute myocardial infarction while on treatment, relative to thiazide diuretic?\n\n\nPatient level prediction\nDisease onset and progression\nFor a given patient who is diagnosed with &lt;insert your favorite disease&gt;, what is the probability that they will go on to have &lt;another disease or related complication&gt; within &lt;time horizon from diagnosis&gt;?\nFor a given patient who is newly diagnosed with atrial fibrillation, what is the probability that they will go onto to have ischemic stroke in next 3 years?\n\n\n\nTreatment response\nFor a given patient who is a new user of &lt;insert your favorite chronically-used drug&gt;, what is the probability that they will &lt;insert desired effect&gt; in &lt;time window&gt;?\nFor a given patient with T2DM who start on metformin, what is the probability that they will maintain HbA1C &lt;6.5% after 3 years?\n\n\n\nTreatment safety\nFor a given patient who is a new user of &lt;insert your favorite drug&gt;, what is the probability that they will experience &lt;insert adverse event&gt; within &lt;time horizon following exposure&gt;?\nFor a given patient who is a new user of warfarin, what is the probability that they will have GI bleed in 1 year?\n\n\n\n\nBack to Table of Contents",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#important-paper-about-implementation-of-the-omop-cdm",
    "href": "resources.html#important-paper-about-implementation-of-the-omop-cdm",
    "title": "6  Resources",
    "section": "11.2 Important Paper About Implementation of the OMOP CDM!",
    "text": "11.2 Important Paper About Implementation of the OMOP CDM!\nErica A Voss, Clair Blacketer, Sebastiaan van Sandijk, Maxim Moinat, Michael Kallfelz, Michel van Speybroeck, Daniel Prieto-Alhambra, Martijn J Schuemie, Peter R Rijnbeek, European Health Data & Evidence Network—learnings from building out a standardized international health data network, Journal of the American Medical Informatics Association, 2023;, ocad214\n\nBack to Table of Contents",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#overview-of-major-clinical-terminologies-and-coding-systems",
    "href": "resources.html#overview-of-major-clinical-terminologies-and-coding-systems",
    "title": "6  Resources",
    "section": "12.1 Overview of Major Clinical Terminologies and Coding Systems",
    "text": "12.1 Overview of Major Clinical Terminologies and Coding Systems\nThis document provides a detailed overview of several essential clinical terminologies and coding systems used in healthcare. Each system has a specific role and is crucial for standardized communication in healthcare settings. The information includes development history, usage, and updates of these systems.\nFor more in-depth information, links to the respective official websites are provided.\n\n12.1.1 SNOMED Clinical Terms (SNOMED CT)\n\nDevelopment: Originally by the College of American Pathologists, now under SNOMED International.\nAdoption: Used in over 50 countries.\nConcepts: Over 340,000 active concepts in 19 hierarchies.\nUsage: Encodes clinical information including diseases, findings, and procedures.\nUpdates: Biannual, with more frequent updates planned.\nMore Information: SNOMED International\n\n\n\n12.1.2 Logical Observation Identifiers Names and Codes (LOINC)\n\nDeveloper: Regenstrief Institute.\nFunction: Identifiers for laboratory and clinical observations.\nContent: Over 90,000 terms.\nCollaboration: With SNOMED CT for coded content development.\nUpdates: Biannual.\nMore Information: LOINC\n\n\n\n12.1.3 RxNorm\n\nDeveloper: National Library of Medicine (NLM).\nFunction: Standard nomenclature for medications.\nIntegration: Links to various drug vocabularies.\nAccess: Requires UMLS user license for proprietary content.\nMore Information: RxNorm - NLM\n\n\n\n12.1.4 International Classification of Disease (ICD)\n\nEndorsement: World Health Organization (WHO).\nVersions: ICD-10 widely used with national extensions; ICD-11 adopted for future use.\nPurpose: Epidemiology, health management, clinical purposes.\nUpdates: Annual, freely available.\nMore Information: WHO ICD\n\n\n\n12.1.5 Current Procedural Terminology (CPT)\n\nDeveloper: American Medical Association (AMA).\nUse: Encoding of medical services and procedures in the USA.\nCategories: Three categories of codes.\nRequirement: License from AMA for use.\nMore Information: CPT - AMA\n\n\n\n12.1.6 Human Phenotype Ontology (HPO)\n\nFunction: Bioinformatic resources for human diseases and phenotypes analysis.\nComponents: Phenotype vocabulary, disease-phenotype annotations, algorithms.\nApplications: Genomic interpretation, gene-disease discovery, precision medicine.\nContent: Over 13,000 terms in 5 hierarchies.\nAvailability: Freely available, multiple releases per year.\nMore Information: Human Phenotype Ontology\n\n\n\n12.1.7 Unified Medical Language System (UMLS)\n\nInitiation: By the US National Library of Medicine in 1986.\nGoal: To aid in the retrieval and integration of electronic biomedical information.\nChallenge Addressed: Different vocabularies expressing the same information differently.\nAvailability: Free, but requires a license due to additional licensing requirements of some contents.\nMore Information: UMLS - NLM\n\n\n\n12.1.8 Ontology Mapping in BioPortal Applications\n\nProcess: Finding the closest match of a code from one ontology in another.\nMatching: Exact equivalence is rare; approximate matching is common.\nChallenges: Labor-intensive and requires understanding the maps’ nature and limitations.\nAlternative Approach: Mapping multiple ontologies to a central core terminology, as used by the OHDSI consortium.\nMore Information: BioPortal\n\nBack to Table of Contents\n\n\nhttps://www.healthit.gov/isa/section-i-vocabularycode-setterminology-standards-and-implementation-specifications",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#omop-domains-by-source-to-standard-vocabulary",
    "href": "resources.html#omop-domains-by-source-to-standard-vocabulary",
    "title": "6  Resources",
    "section": "12.2 OMOP Domains by Source to Standard Vocabulary",
    "text": "12.2 OMOP Domains by Source to Standard Vocabulary\ngraph LR\n    ICD9(\"ICD9\") --&gt;|Transformation to OMOP CDM| SNOMED(\"STANDARD&lt;br&gt;Vocabulary Concept Code&lt;br&gt;SNOMED\")\n    ICD10(\"ICD10\") --&gt;|Transformation to OMOP CDM| SNOMED\n\nBack to Table of Contents\n\n\n\n\n\n\n\n\n\nDomain\nSource Vocabulary\nStandard Vocabulary\n\n\n\n\nConditions\nICD9, ICD10\nSNOMED\n\n\nMeasurements\nLOINC or institutional specific codes\nLOINC\n\n\nDrugs\nNDC\nRxNORM\n\n\nProcedures\nICD9, ICD10, CPT\nSNOMED\n\n\n\n\nICD = International Classification of Diseases\nSNOMED = Systematized Nomenclature of Medicine\nLOINC = Logical Observation Identifiers Names and Codes\nNDC = National Drug Code\nCPT = Current Procedural Terminology\n\nBack to Table of Contents",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#incremental-loading",
    "href": "resources.html#incremental-loading",
    "title": "6  Resources",
    "section": "12.3 Incremental Loading",
    "text": "12.3 Incremental Loading\nIncremental loading in the context of OHDSI refers to the process of adding new or updated data to an existing OHDSI database without the need to completely rebuild or refresh the entire dataset. This can be particularly useful for large datasets where full loads can be time-consuming and inefficient. The process involves extracting only the changes since the last load and then transforming and loading this delta of data into the existing OMOP Common Data Model (CDM) used by OHDSI tools.\nFor instance, in the development of an ETL (Extract, Transform, Load) process for the bulk and incremental load of German patient data into the OMOP CDM using FHIR as referenced by OHDSI, it suggests that the incremental loading is an essential part of keeping the database up-to-date in an efficient manner​. OHDSI Symposium Showcase #44\nThis group alos described a Near Real-Time Incremental OMOP-CDM ETL System\nThis is also described by Dr. DuWayne Willett, CMIO of UTSW, at around minute 30 of this video:\n\n\n\nOHDSI Symposium Presentation\n\n\n…and in this OHDSI symposium presentation: .\n\nBack to Table of Contents",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#current-cdm",
    "href": "resources.html#current-cdm",
    "title": "6  Resources",
    "section": "12.4 Current CDM",
    "text": "12.4 Current CDM\n\n\n\nCDM54 Image\n\n\nSource: OHDSI Common Data Model\n\nBack to Table of Contents\n\nInteractive (Select) OMOP Data Dictionary\n\nBack to Table of Contents",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#etl-steps",
    "href": "resources.html#etl-steps",
    "title": "6  Resources",
    "section": "15.1 ETL STEPS",
    "text": "15.1 ETL STEPS\n\nDataset profiling and documentation\n\nCreate data model documentation, sample data, data dictionaries, code lists, and other relevant information (23-Aug)\nExecute database profiling scan (WhiteRabbit) on source database\nPrepare mapping approach/documents based on scan reports from database profiling scan\n\nGeneration of the ETL Design\n\nMapping workshop with all relevant parties to:\n\nUnderstand the source\nDefine the scope of source data to be transformed\nDefine acceptance criteria for OMOP output\n\n\nOutput: draft mapping document\n\nFinalize mapping document:\n\nIntegrate all notes/documentation from workshop\nWork through mappings and verify, update, fill in gaps\nMeetings/emails with data contact/technical contact (TC) as needed\n\n\nSource Data Integrations and Semantic Mapping\n\nSource Code mapping:\n\nIdentify which codes are already mapped to standard vocabulary\nIdentify code types for codes that need to be mapped\nTranslation of code description/phrases to English, if/as needed\nCreate proposed code mappings\n\nGenerate mappings for data coming out of flowsheets (together with consortium)\nReview/approval of code mappings, often done by medical experts affiliated with Data Owner (DO).\nIdentify medical imaging available and define mappings to Imaging Extension\nIdentify waveform data available and map using consortium-defined guidelines\nUse OHNLP to extract OMOP data from unstructured sources\n\nTechnical architecture design\n\nContinuous Integration, Continuous Deployment (CI/CD):\n\nDecide on ETL dev/deployment flow\nPut version control mechanisms in place\n\nOHDSI Ecosystem:\n\nEvaluate infrastructure needed\nCreate infrastructure design documentation\n\n\nTechnical ETL Development\n\nImplement ETL (Preferred Language/Structure?)\nUpdate ETL based on testing/QA/feedback (8, 9)\n\nSetting up of Infrastructure\n\nDeploy core servers and associated services based on infrastructure design in (4)\n\nInstallation of the OHDSI tools\n\nInstall and configure all software (database server, Achilles/DQD/Ares, Atlas/WebAPI, R Studio server, HADES, notebooks/tooling related to analytics, and any other software to suit a site’s specific needs).\n\nETL Testing and Validation\n\nETL Execution:\n\nTest ETL using sample/development data (with limited external data access)\nTest ETL using DO data (with full external data access)\nVerify and document QA\nSubmit Achilles/DQD/AresIndexer results to central location regularly\n\nETL Development Planning and Management:\n\nReview ETL testing and progress (TCs/meetings)\n\n\nData Quality Assessment\n\nQA/Acceptance testing:\n\nEvaluate accuracy and completeness of mapping\nReview and approval by DO\n\n\nDocumentation\n\nMapping Documentation and Themis Checks\nTransformation/Technical Documentation\n\nProject Management Througout\n\nOrganization of tasks, milestones, and follow-up",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#data-science-handbook",
    "href": "resources.html#data-science-handbook",
    "title": "6  Resources",
    "section": "16.1 Data Science Handbook",
    "text": "16.1 Data Science Handbook\nOpen, rigorous and reproducible research: A practitioner’s handbook From Standord Data Science\n\nBack to Table of Contents",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#data-management-tools-and-resources",
    "href": "resources.html#data-management-tools-and-resources",
    "title": "6  Resources",
    "section": "16.2 Data Management Tools and resources",
    "text": "16.2 Data Management Tools and resources\nDMP Tool: https://dmptool.org/ https://sharing.nih.gov/data-management-and-sharing-policy/planning-and-budgeting-for-data-management-and-sharing/writing-a-data-management-and-sharing-plan#after",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#programming-resources-jupyter-notebooks-python-sql-and-r-programming-resources",
    "href": "resources.html#programming-resources-jupyter-notebooks-python-sql-and-r-programming-resources",
    "title": "6  Resources",
    "section": "16.3 Programming Resources: Jupyter Notebooks, Python, SQL, and R Programming Resources",
    "text": "16.3 Programming Resources: Jupyter Notebooks, Python, SQL, and R Programming Resources\n\nProject Jupyter\nWhat is the Jupyter Notebook?\nNIAID NIH Informatics resources\n\nSoftware Carpentry is a website that provides free online lessons to researchers wanting to enhance their programming skills for data analysis. This website offers free online lessons on a variety of useful topics including:\n\nProgramming with Python\nProgramming with R\nDatabases and SQL\n\nAdditional resources:\n\nDataCamp\nKhan Academy\nCodecademy - Learn Python 2\nPython Data Science Handbook\nR for Data Science\nIntroduction to Programming (NIAID, NIH)\nPython Programming (NIAID, NIH)\nData Analysis with Python and Pandas (NIAID, NIH)\nData Visualization with Python (NIAID, NIH)\nSource:NIH All of US Study\n\n\nBack to Table of Contents",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#ohdsi-community",
    "href": "resources.html#ohdsi-community",
    "title": "6  Resources",
    "section": "21.1 OHDSI Community",
    "text": "21.1 OHDSI Community\nBroadsea3.0\nBy: Lee Evans\n\n\nBack to Table of Contents",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#tufts-bridge2ai-standards-module",
    "href": "resources.html#tufts-bridge2ai-standards-module",
    "title": "6  Resources",
    "section": "21.2 Tufts Bridge2AI Standards Module",
    "text": "21.2 Tufts Bridge2AI Standards Module\n\nJune 15, 2023:\nData Quality Dashboard\nBy: Jared Houghtaling\n\nJuly 6, 2023:\nData Quality Dashboard output demo\nBy: Jared Houghtaling\n\nJuly 13, 2023:\nAchilles output demo\nBy: Jared Houghtaling\n\nJuly 27, 2023:\nFlowsheet follow-up\nBy: Polina Talapova & Jared Houghtaling\n\nAugust 3, 2023:\nOMOP Standardized Vocabularies - Part 1\nBy: Jared Houghtaling and Polina Talapova\n\nAugust 17, 2023:\nOMOP Standardized Vocabularies - Part 2\nBy: Polina Talapova\n\nAugust 24, 2023:\nHow to download and set-up a DDL (Demo)\nBy: Jared Houghtaling\n\nAugust 31, 2023:\nDemo of WhiteRabbit and RabbitInAHat\nBy: Jared Houghtaling\n\nSeptember 7, 2023:\nARES usefulness for ETL at Tufts\nBy: Jared Houghtaling\n\nSeptember 21, 2023:\nSample ETL Process\nBy: Jared Houghtaling\n\n\nOctober 12, 2023:\nGoogle Form for Site Progress Tracking\nWith Jared Houghtaling and Andrew Williams\n\n\nOctober 26, 2023:\nReview and Prioritization of DQD Results, and Discussion of DQD Issue Severity\nWith Jared Houghtaling\n\nNovember 2, 2023:\nPrinciples of Mapping and Vocab Gaps Identification\nWith Polina Talapova\n\nNovember 9, 2023:\nUsagi & STCM Demo\nWith Polina Talapova & Jared Houghtailing\n\n\n\nBack to Table of Contents",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#this-is-the-main-redcap-training-page-redcap-resources",
    "href": "resources.html#this-is-the-main-redcap-training-page-redcap-resources",
    "title": "6  Resources",
    "section": "23.1 This is the main REDCap training page: REDCap Resources",
    "text": "23.1 This is the main REDCap training page: REDCap Resources\nFrom University of Colorado, below are excellent REDCap resources: University of Colorado REDCap Resources",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#analysis-with-sql-ohdsiomop",
    "href": "resources.html#analysis-with-sql-ohdsiomop",
    "title": "6  Resources",
    "section": "23.2 Analysis with SQL (OHDSI/OMOP)",
    "text": "23.2 Analysis with SQL (OHDSI/OMOP)\nThe OMOP Query Library is a library of commonly-used SQL queries for the OMOP Common Data Model (CDM).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#analysis-with-r",
    "href": "resources.html#analysis-with-r",
    "title": "6  Resources",
    "section": "23.3 Analysis with R",
    "text": "23.3 Analysis with R\nBelow are some sample R queries that demonstrate how to read in OMOP tables from CSV files, join them based on the person_id and visit_occurrence_id fields, and search for specific criteria.\nNote: Adjust the file paths and column names accordingly based on the actual structure and location of your CSV files. The queries below are a generic representation and may need adjustments based on the specifics of your data set.\n\n23.3.1 Reading CSV files into R data frames:\n# Read the CSV files into R data frames\nperson_df &lt;- read.csv(\"path_to_person_table.csv\", header=TRUE, stringsAsFactors=FALSE)\nvisit_occurrence_df &lt;- read.csv(\"path_to_visit_occurrence_table.csv\", header=TRUE, stringsAsFactors=FALSE)\ncondition_occurrence_df &lt;- read.csv(\"path_to_condition_occurrence_table.csv\", header=TRUE, stringsAsFactors=FALSE)\nJoin tables based on person_id:\nWhen a person has multiple visits in the visit_occurrence table, joining the person table with the visit_occurrence table will result in multiple rows for that person, each corresponding to a different visit. This is a standard one-to-many join operation.\n## Join person with visit_occurrence on 'person_id'\nperson_visit_df &lt;- merge(person_df, visit_occurrence_df, by=\"person_id\")\n\n\n23.3.2 Joining the Person-Visit table with the Condition Occurrence table:\n# Join the person-visit result with condition_occurrence on both 'person_id' and 'visit_occurrence_id'\nfull_df &lt;- merge(person_visit_df, condition_occurrence_df, by=c(\"person_id\", \"visit_occurrence_id\"))\n\n\n23.3.3 Search by a list of person_ids:\n# Define a list of person_ids to search for\nsearch_person_ids &lt;- c(1, 2, 3, 4, 5)\n\n# Filter the data frame to only include rows with person_ids in the list\nfiltered_by_person_df &lt;- subset(full_df, person_id %in% search_person_ids)\n\n\n23.3.4 Search by a specific condition concept code:\n# Define a specific condition concept code to search for\nsearch_condition_concept_id &lt;- 1234567\n\n# Filter the data frame to only include rows with the specified condition concept code\nfiltered_by_condition_df &lt;- subset(full_df, condition_concept_id == search_condition_concept_id)\n\n\n23.3.5 Search by a date range:\n# Define a date range to search for\nstart_date &lt;- as.Date(\"2020-01-01\")\nend_date &lt;- as.Date(\"2020-12-31\")\n\n## Filter the data frame to only include rows within the date range\nfiltered_by_date_df &lt;- subset(full_df, visit_start_date &gt;= start_date & visit_start_date &lt;= end_date)\n\n\nBack to Table of Contents\n\n\n## Markdown Content for GitHub Tutorial\n\n# Tutorial for Analyzing Type 2 Diabetes First Occurrence in OMOP CDM Data\n\nThis tutorial demonstrates how to create a flat file that consolidates information for each `person_id` based on the first occurrence of type 2 diabetes (standard concept ID 201826) using various data analysis tools: SQL, SAS, R, Stata, and SPSS.\n\nRemember to adjust file paths and variable specifics according to your dataset.\n\n## SQL\n\n### Loading Data\nAssuming the data are already loaded into a SQL database.\n\n### SQL Query\n```sql\nSELECT\n    p.*,\n    vo.*,\n    co.condition_occurrence_id,\n    de.drug_exposure_id,\n    m.measurement_id\nFROM\n    person p\nJOIN\n    condition_occurrence co ON p.person_id = co.person_id\nJOIN\n    visit_occurrence vo ON co.visit_occurrence_id = vo.visit_occurrence_id\nLEFT JOIN\n    drug_exposure de ON p.person_id = de.person_id AND vo.visit_occurrence_id = de.visit_occurrence_id\nLEFT JOIN\n    measurement m ON p.person_id = m.person_id AND vo.visit_occurrence_id = m.visit_occurrence_id\nWHERE\n    co.condition_concept_id = 201826\nAND\n    co.condition_start_date = (\n        SELECT MIN(condition_start_date)\n        FROM condition_occurrence\n        WHERE person_id = co.person_id AND condition_concept_id = 201826\n    )\nGROUP BY\n    p.person_id;",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#sas",
    "href": "resources.html#sas",
    "title": "6  Resources",
    "section": "23.4 SAS",
    "text": "23.4 SAS\n\n23.4.1 Loading Data\nlibname mydata '/path/to/csv/files';\n\nproc import datafile=\"/path/to/csv/person.csv\" \n    out=mydata.person \n    dbms=csv \n    replace;\nrun;\n\n… [Repeat for other CSV files]\n\n\n23.4.2 SAS Code\nproc sql;\n    create table first_diabetes_visit as\n    select\n        p.*,\n        vo.*,\n        co.condition_occurrence_id,\n        de.drug_exposure_id,\n        m.measurement_id\n    from\n        mydata.person p\n    inner join\n        mydata.condition_occurrence co on p.person_id = co.person_id\n    inner join\n        mydata.visit_occurrence vo on co.visit_occurrence_id = vo.visit_occurrence_id\n    left join\n        mydata.drug_exposure de on p.person_id = de.person_id and vo.visit_occurrence_id = de.visit_occurrence_id\n    left join\n        mydata.measurement m on p.person_id = m.person_id and vo.visit_occurrence_id = m.visit_occurrence_id\n    where\n        co.condition_concept_id = 201826\n    and\n        co.condition_start_date = (\n            select min(condition_start_date)\n            from mydata.condition_occurrence\n            where person_id = co.person_id and condition_concept_id = 201826\n        )\n    group by\n        p.person_id;\nquit;",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#r",
    "href": "resources.html#r",
    "title": "6  Resources",
    "section": "23.5 R",
    "text": "23.5 R\n\n23.5.1 Loading Data\nlibrary(readr)\n\nperson &lt;- read_csv(\"path/to/csv/person.csv\")\nvisit_occurrence &lt;- read_csv(\"path/to/csv/visit_occurrence.csv\")\ncondition_occurrence &lt;- read_csv(\"path/to/csv/condition_occurrence.csv\")\ndrug_exposure &lt;- read_csv(\"path/to/csv/drug_exposure.csv\")\nmeasurement &lt;- read_csv(\"path/to/csv/measurement.csv\")\n\n\n23.5.2 R Code\nlibrary(dplyr)\n\nfirst_diabetes_visit &lt;- condition_occurrence %&gt;%\n  filter(condition_concept_id == 201826) %&gt;%\n  group_by(person_id) %&gt;%\n  summarize(first_diagnosis_date = min(condition_start_date)) %&gt;%\n  inner_join(visit_occurrence, by = \"person_id\") %&gt;%\n  inner_join(person, by = \"person_id\") %&gt;%\n  left_join(drug_exposure, by = c(\"person_id\", \"visit_occurrence_id\")) %&gt;%\n  left_join(measurement, by = c(\"person_id\", \"visit_occurrence_id\")) %&gt;%\n  filter(condition_start_date == first_diagnosis_date)\n\nwrite.csv(first_diabetes_visit, \"first_diabetes_visit.csv\", row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#stata",
    "href": "resources.html#stata",
    "title": "6  Resources",
    "section": "23.6 Stata",
    "text": "23.6 Stata\n\n23.6.1 Loading Data\nimport delimited \"path/to/csv/person.csv\", clear\nsave person, replace\n\n… [Repeat for other CSV files]\n\n\n23.6.2 Stata Code\nAssuming data are already loaded and named appropriately\nmerge 1:1 person_id using condition_occurrence\nmerge 1:1 person_id using visit_occurrence\nmerge 1:1 person_id using drug_exposure\nmerge 1:1 person_id using measurement\n\nFiltering for first occurrence of type 2 diabetes\negen min_date = min(cond(condition_concept_id == 201826, condition_start_date, .)), by(person_id\n\n)\nkeep if condition_start_date == min_date\n\nExporting the dataset\nexport delimited using \"first_diabetes_visit.csv\", replace",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#spss",
    "href": "resources.html#spss",
    "title": "6  Resources",
    "section": "23.7 SPSS",
    "text": "23.7 SPSS\n\n23.7.1 Loading Data\nGET DATA\n  /TYPE=TXT\n  /FILE='path/to/csv/person.csv'\n  /DELCASE=LINE\n  /DELIMITERS=\",\"\n  /ARRANGEMENT=DELIMITED\n  /FIRSTCASE=2\n  /VARIABLES=\n  … [Variable names and types]\nCACHE.\nEXECUTE.\n\n… [Repeat for other CSV files]\n\n\n23.7.2 SPSS Code\nMATCH FILES\n  /FILE=*\n  /TABLE='condition_occurrence'\n  /BY person_id.\nMATCH FILES\n  /FILE=*\n  /TABLE='visit_occurrence'\n  /BY person_id.\nMATCH FILES\n  /FILE=*\n  /TABLE='drug_exposure'\n  /BY person_id.\nMATCH FILES\n  /FILE=*\n  /TABLE='measurement'\n  /BY person_id.\n\nFiltering for first occurrence of type 2 diabetes.\nAGGREGATE OUTFILE=* MODE=ADDVARIABLES OVERWRITE=YES\n/BREAK=person_id\n/first_diagnosis_date=MIN(condition_start_date (condition_concept_id = 201826)).\n\nSELECT IF condition_start_date = first_diagnosis_date.\n\nExporting the dataset.\nSAVE OUTFILE='path/to/output/first_diabetes_visit.sav'.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#python",
    "href": "resources.html#python",
    "title": "6  Resources",
    "section": "23.8 Python",
    "text": "23.8 Python\n\n23.8.1 Loading Data\nimport pandas as pd\n\nperson = pd.read_csv('path/to/csv/person.csv')\nvisit_occurrence = pd.read_csv('path/to/csv/visit_occurrence.csv')\ncondition_occurrence = pd.read_csv('path/to/csv/condition_occurrence.csv')\ndrug_exposure = pd.read_csv('path/to/csv/drug_exposure.csv')\nmeasurement = pd.read_csv('path/to/csv/measurement.csv')\n\n\n23.8.2 Python Code\nFiltering for first occurrence of type 2 diabetes\nfirst_diagnosis = condition_occurrence[condition_occurrence['condition_concept_id'] == 201826]\nfirst_diagnosis = first_diagnosis.groupby('person_id')['condition_start_date'].min().reset_index()\n\nMerging with other dataframes\nmerged_data = first_diagnosis.merge(visit_occurrence, on='person_id')\nmerged_data = merged_data.merge(person, on='person_id')\nmerged_data = merged_data.merge(drug_exposure, on=['person_id', 'visit_occurrence_id'], how='left')\nmerged_data = merged_data.merge(measurement, on=['person_id', 'visit_occurrence_id'], how='left')\n\nFiltering to keep only records corresponding to the first diabetes diagnosis\nmerged_data = merged_data[merged_data['condition_start_date'] == merged_data['first_diagnosis_date']]\n\nExporting the dataset\nmerged_data.to_csv('first_diabetes_visit.csv', index=False)\n```\n\n\n23.8.3 SAMPLE OHDSI Network Study TABLE\n\n23.8.3.1 Study Information\n\n\n\n\n\n\n\nElement\nDescription\n\n\n\n\nStudy Title\nCreation and Evaluation of XX Across Different Database Sources\n\n\nStudy Status\nStudy Status: Started\n\n\nNext Steps\nGenerate the 8 phenotypes on multiple external OMOP CDMs (at least 1 claims and 1 EHR based CDMs) and run Phevaluator on external CDMs\n\n\nResearch Question\nHow do XXX phenotypes perform across different data sources (EHR, claims, registries) that may have differences in how the OMOP ETL was performed?\n\n\nUncertainty\nWe remain uncertain as to how our phenotypes will perform across other database types (claims, other EHR, etc).\n\n\nStudy type\nClinical Application.\n\n\nTags\nOHDSI XXX\n\n\nStudy lead\nDr. XXX\n\n\nStudy lead forums tag\nN/A (The OHDSI forums tag of the study lead, which can be used to contact the lead. It is recommended to make this a hyperlink to lead’s forums profile)\n\n\nStudy team\nXXX, XXX, XXX\n\n\nPhenotype Development\nCreated and tested X# phenotypes with Phevaluator using XXX Institution OMOP CDM\n\n\nPhenotype Evaluation\nCurrently under development process. This is the purpose of the study\n\n\nCohort Definitions\nXXX Phenotype Cohort IDs (ATLAS Demo): #, #, #\n\n\nCohort Diagnostics\nCurrently under development process. (A hyperlink to the R Shiny app where the cohort diagnostics results can be viewed.)\n\n\nAnalysis Specifications\nDevelop a OHDSI protocol to run a multi-centric patient level prediction study on complication comparisons among different drug use for XX patients.\n\n\nHADES Packages\nROhdsiWebApi, DatabaseConnecter, CohortDiagnostics, Phevaluator\n\n\nStudy Sites\nPending, but likely to include X, X, X, and other datasources accessed through XX\n\n\nResults explorer\nN/A\n\n\nStudy start date\nJuly 9, 2024\n\n\nStudy end date\nNot complete yet\n\n\nProtocol\nSee documents directory\n\n\nPublications\nN/A (Zero, one or more hyperlinks to papers produced as part of the study (comma-separated).)\n\n\n\n\n\n23.8.3.2 Study Progress\n\n\n\n\n\n\n\nStudy Attribute\nValue\n\n\n\n\nIRB materials sufficient for review\nYes\n\n\nCohort definition(s) available\nYes\n\n\nData partner recruitment status\nReady\n\n\nDeadline for adding new data partners\nN/A\n\n\nProtocol building team recruitment status\nReady\n\n\nDeadline for adding new protocol building team members\nN/A\n\n\nManuscript preparation team recruitment status\nReady\n\n\nDeadline for adding new manuscript preparation team members\nN/A",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Resources</span>"
    ]
  }
]